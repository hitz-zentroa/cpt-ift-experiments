{
  "results": {
    "eus_exams_eu_ejadministrari": {
      "alias": "eus_exams_eu_ejadministrari",
      "acc,none": 0.22844827586206898,
      "acc_stderr,none": 0.01592516948704031,
      "acc_norm,none": 0.22844827586206898,
      "acc_norm_stderr,none": 0.01592516948704031
    },
    "eus_exams_eu_ejlaguntza": {
      "alias": "eus_exams_eu_ejlaguntza",
      "acc,none": 0.2570281124497992,
      "acc_stderr,none": 0.0196019063387535,
      "acc_norm,none": 0.2570281124497992,
      "acc_norm_stderr,none": 0.0196019063387535
    },
    "eus_exams_eu_ejlaguntzaile": {
      "alias": "eus_exams_eu_ejlaguntzaile",
      "acc,none": 0.2539454806312769,
      "acc_stderr,none": 0.01649874487991116,
      "acc_norm,none": 0.2539454806312769,
      "acc_norm_stderr,none": 0.01649874487991116
    },
    "eus_exams_eu_ejteknikari": {
      "alias": "eus_exams_eu_ejteknikari",
      "acc,none": 0.23435225618631733,
      "acc_stderr,none": 0.01617286700382679,
      "acc_norm,none": 0.23435225618631733,
      "acc_norm_stderr,none": 0.01617286700382679
    },
    "eus_exams_eu_opebilbaoeu": {
      "alias": "eus_exams_eu_opebilbaoeu",
      "acc,none": 0.24285714285714285,
      "acc_stderr,none": 0.017097752760991916,
      "acc_norm,none": 0.24285714285714285,
      "acc_norm_stderr,none": 0.017097752760991916
    },
    "eus_exams_eu_opeehuadmineu": {
      "alias": "eus_exams_eu_opeehuadmineu",
      "acc,none": 0.250501002004008,
      "acc_stderr,none": 0.019416707602848898,
      "acc_norm,none": 0.250501002004008,
      "acc_norm_stderr,none": 0.019416707602848898
    },
    "eus_exams_eu_opeehuauxeu": {
      "alias": "eus_exams_eu_opeehuauxeu",
      "acc,none": 0.25333333333333335,
      "acc_stderr,none": 0.020525151909925377,
      "acc_norm,none": 0.25333333333333335,
      "acc_norm_stderr,none": 0.020525151909925377
    },
    "eus_exams_eu_opeehubiblioeu": {
      "alias": "eus_exams_eu_opeehubiblioeu",
      "acc,none": 0.25208681135225375,
      "acc_stderr,none": 0.017756201558991255,
      "acc_norm,none": 0.25208681135225375,
      "acc_norm_stderr,none": 0.017756201558991255
    },
    "eus_exams_eu_opeehuderechoeu": {
      "alias": "eus_exams_eu_opeehuderechoeu",
      "acc,none": 0.24571428571428572,
      "acc_stderr,none": 0.016283379956833405,
      "acc_norm,none": 0.24571428571428572,
      "acc_norm_stderr,none": 0.016283379956833405
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "alias": "eus_exams_eu_opeehueconomicaseu",
      "acc,none": 0.2621082621082621,
      "acc_stderr,none": 0.023507294979756434,
      "acc_norm,none": 0.2621082621082621,
      "acc_norm_stderr,none": 0.023507294979756434
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "alias": "eus_exams_eu_opeehuempresarialeseu",
      "acc,none": 0.26785714285714285,
      "acc_stderr,none": 0.026512301457877488,
      "acc_norm,none": 0.26785714285714285,
      "acc_norm_stderr,none": 0.026512301457877488
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "alias": "eus_exams_eu_opeehusubalternoeu",
      "acc,none": 0.2425,
      "acc_stderr,none": 0.021456591955524174,
      "acc_norm,none": 0.2425,
      "acc_norm_stderr,none": 0.021456591955524174
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "alias": "eus_exams_eu_opeehutecnicoeu",
      "acc,none": 0.24892703862660945,
      "acc_stderr,none": 0.01636625783469581,
      "acc_norm,none": 0.24892703862660945,
      "acc_norm_stderr,none": 0.01636625783469581
    },
    "eus_exams_eu_opeehuteknikarib": {
      "alias": "eus_exams_eu_opeehuteknikarib",
      "acc,none": 0.2387312186978297,
      "acc_stderr,none": 0.017433035947187103,
      "acc_norm,none": 0.2387312186978297,
      "acc_norm_stderr,none": 0.017433035947187103
    },
    "eus_exams_eu_opegasteizkoudala": {
      "alias": "eus_exams_eu_opegasteizkoudala",
      "acc,none": 0.3388888888888889,
      "acc_stderr,none": 0.02498150903224174,
      "acc_norm,none": 0.3388888888888889,
      "acc_norm_stderr,none": 0.02498150903224174
    },
    "eus_exams_eu_opeosakiadmineu": {
      "alias": "eus_exams_eu_opeosakiadmineu",
      "acc,none": 0.2245762711864407,
      "acc_stderr,none": 0.027221844295269436,
      "acc_norm,none": 0.2245762711864407,
      "acc_norm_stderr,none": 0.027221844295269436
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "alias": "eus_exams_eu_opeosakiauxenfeu",
      "acc,none": 0.2934131736526946,
      "acc_stderr,none": 0.03534016139050468,
      "acc_norm,none": 0.2934131736526946,
      "acc_norm_stderr,none": 0.03534016139050468
    },
    "eus_exams_eu_opeosakiauxeu": {
      "alias": "eus_exams_eu_opeosakiauxeu",
      "acc,none": 0.23636363636363636,
      "acc_stderr,none": 0.03317505930009174,
      "acc_norm,none": 0.23636363636363636,
      "acc_norm_stderr,none": 0.03317505930009174
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "alias": "eus_exams_eu_opeosakiceladoreu",
      "acc,none": 0.26380368098159507,
      "acc_stderr,none": 0.03462419931615622,
      "acc_norm,none": 0.26380368098159507,
      "acc_norm_stderr,none": 0.03462419931615622
    },
    "eus_exams_eu_opeosakienfeu": {
      "alias": "eus_exams_eu_opeosakienfeu",
      "acc,none": 0.2386058981233244,
      "acc_stderr,none": 0.022099063590345268,
      "acc_norm,none": 0.2386058981233244,
      "acc_norm_stderr,none": 0.022099063590345268
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "alias": "eus_exams_eu_opeosakioperarioeu",
      "acc,none": 0.22137404580152673,
      "acc_stderr,none": 0.03641297081313727,
      "acc_norm,none": 0.22137404580152673,
      "acc_norm_stderr,none": 0.03641297081313727
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "alias": "eus_exams_eu_opeosakitecnicoeu",
      "acc,none": 0.21806853582554517,
      "acc_stderr,none": 0.023083723263674347,
      "acc_norm,none": 0.21806853582554517,
      "acc_norm_stderr,none": 0.023083723263674347
    },
    "eus_exams_eu_opeosakivarioseu": {
      "alias": "eus_exams_eu_opeosakivarioseu",
      "acc,none": 0.2518796992481203,
      "acc_stderr,none": 0.026666091559782525,
      "acc_norm,none": 0.2518796992481203,
      "acc_norm_stderr,none": 0.026666091559782525
    },
    "eus_exams_eu_osakidetza1e": {
      "alias": "eus_exams_eu_osakidetza1e",
      "acc,none": 0.2642967542503864,
      "acc_stderr,none": 0.01734926145335676,
      "acc_norm,none": 0.2642967542503864,
      "acc_norm_stderr,none": 0.01734926145335676
    },
    "eus_exams_eu_osakidetza2e": {
      "alias": "eus_exams_eu_osakidetza2e",
      "acc,none": 0.22994652406417113,
      "acc_stderr,none": 0.015396200792468366,
      "acc_norm,none": 0.22994652406417113,
      "acc_norm_stderr,none": 0.015396200792468366
    },
    "eus_exams_eu_osakidetza3e": {
      "alias": "eus_exams_eu_osakidetza3e",
      "acc,none": 0.23679417122040072,
      "acc_stderr,none": 0.018160009189222222,
      "acc_norm,none": 0.23679417122040072,
      "acc_norm_stderr,none": 0.018160009189222222
    },
    "eus_exams_eu_osakidetza5e": {
      "alias": "eus_exams_eu_osakidetza5e",
      "acc,none": 0.2246153846153846,
      "acc_stderr,none": 0.01638158769542526,
      "acc_norm,none": 0.2246153846153846,
      "acc_norm_stderr,none": 0.01638158769542526
    },
    "eus_exams_eu_osakidetza6e": {
      "alias": "eus_exams_eu_osakidetza6e",
      "acc,none": 0.207,
      "acc_stderr,none": 0.012818553557844009,
      "acc_norm,none": 0.207,
      "acc_norm_stderr,none": 0.012818553557844009
    },
    "eus_exams_eu_osakidetza7e": {
      "alias": "eus_exams_eu_osakidetza7e",
      "acc,none": 0.24780397595931578,
      "acc_stderr,none": 0.0092852116379216,
      "acc_norm,none": 0.24780397595931578,
      "acc_norm_stderr,none": 0.0092852116379216
    }
  },
  "group_subtasks": {
    "eus_exams_eu_osakidetza1e": [],
    "eus_exams_eu_opeosakiceladoreu": [],
    "eus_exams_eu_opeosakiadmineu": [],
    "eus_exams_eu_opeehutecnicoeu": [],
    "eus_exams_eu_ejlaguntza": [],
    "eus_exams_eu_ejadministrari": [],
    "eus_exams_eu_osakidetza3e": [],
    "eus_exams_eu_opeosakiauxenfeu": [],
    "eus_exams_eu_opeehuadmineu": [],
    "eus_exams_eu_opeosakiauxeu": [],
    "eus_exams_eu_osakidetza5e": [],
    "eus_exams_eu_opeosakienfeu": [],
    "eus_exams_eu_opeosakivarioseu": [],
    "eus_exams_eu_osakidetza6e": [],
    "eus_exams_eu_opeehusubalternoeu": [],
    "eus_exams_eu_ejlaguntzaile": [],
    "eus_exams_eu_opeehuteknikarib": [],
    "eus_exams_eu_opeosakitecnicoeu": [],
    "eus_exams_eu_osakidetza2e": [],
    "eus_exams_eu_opeehubiblioeu": [],
    "eus_exams_eu_opeosakioperarioeu": [],
    "eus_exams_eu_opeehuauxeu": [],
    "eus_exams_eu_ejteknikari": [],
    "eus_exams_eu_opeehueconomicaseu": [],
    "eus_exams_eu_opegasteizkoudala": [],
    "eus_exams_eu_osakidetza7e": [],
    "eus_exams_eu_opebilbaoeu": [],
    "eus_exams_eu_opeehuempresarialeseu": [],
    "eus_exams_eu_opeehuderechoeu": []
  },
  "configs": {
    "eus_exams_eu_ejadministrari": {
      "task": "eus_exams_eu_ejadministrari",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejadministrari",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejlaguntza": {
      "task": "eus_exams_eu_ejlaguntza",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejlaguntza",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejlaguntzaile": {
      "task": "eus_exams_eu_ejlaguntzaile",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejlaguntzaile",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejteknikari": {
      "task": "eus_exams_eu_ejteknikari",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejteknikari",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opebilbaoeu": {
      "task": "eus_exams_eu_opebilbaoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opebilbaoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuadmineu": {
      "task": "eus_exams_eu_opeehuadmineu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuadmineu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuauxeu": {
      "task": "eus_exams_eu_opeehuauxeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuauxeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehubiblioeu": {
      "task": "eus_exams_eu_opeehubiblioeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehubiblioeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuderechoeu": {
      "task": "eus_exams_eu_opeehuderechoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuderechoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "task": "eus_exams_eu_opeehueconomicaseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehueconomicaseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "task": "eus_exams_eu_opeehuempresarialeseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuempresarialeseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "task": "eus_exams_eu_opeehusubalternoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehusubalternoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "task": "eus_exams_eu_opeehutecnicoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehutecnicoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuteknikarib": {
      "task": "eus_exams_eu_opeehuteknikarib",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuteknikarib",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opegasteizkoudala": {
      "task": "eus_exams_eu_opegasteizkoudala",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opegasteizkoudala",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiadmineu": {
      "task": "eus_exams_eu_opeosakiadmineu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiadmineu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "task": "eus_exams_eu_opeosakiauxenfeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiauxenfeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiauxeu": {
      "task": "eus_exams_eu_opeosakiauxeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiauxeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "task": "eus_exams_eu_opeosakiceladoreu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiceladoreu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakienfeu": {
      "task": "eus_exams_eu_opeosakienfeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakienfeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "task": "eus_exams_eu_opeosakioperarioeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakioperarioeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "task": "eus_exams_eu_opeosakitecnicoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakitecnicoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakivarioseu": {
      "task": "eus_exams_eu_opeosakivarioseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakivarioseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza1e": {
      "task": "eus_exams_eu_osakidetza1e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza1e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza2e": {
      "task": "eus_exams_eu_osakidetza2e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza2e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza3e": {
      "task": "eus_exams_eu_osakidetza3e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza3e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza5e": {
      "task": "eus_exams_eu_osakidetza5e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza5e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza6e": {
      "task": "eus_exams_eu_osakidetza6e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza6e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza7e": {
      "task": "eus_exams_eu_osakidetza7e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza7e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    }
  },
  "versions": {
    "eus_exams_eu_ejadministrari": 0.0,
    "eus_exams_eu_ejlaguntza": 0.0,
    "eus_exams_eu_ejlaguntzaile": 0.0,
    "eus_exams_eu_ejteknikari": 0.0,
    "eus_exams_eu_opebilbaoeu": 0.0,
    "eus_exams_eu_opeehuadmineu": 0.0,
    "eus_exams_eu_opeehuauxeu": 0.0,
    "eus_exams_eu_opeehubiblioeu": 0.0,
    "eus_exams_eu_opeehuderechoeu": 0.0,
    "eus_exams_eu_opeehueconomicaseu": 0.0,
    "eus_exams_eu_opeehuempresarialeseu": 0.0,
    "eus_exams_eu_opeehusubalternoeu": 0.0,
    "eus_exams_eu_opeehutecnicoeu": 0.0,
    "eus_exams_eu_opeehuteknikarib": 0.0,
    "eus_exams_eu_opegasteizkoudala": 0.0,
    "eus_exams_eu_opeosakiadmineu": 0.0,
    "eus_exams_eu_opeosakiauxenfeu": 0.0,
    "eus_exams_eu_opeosakiauxeu": 0.0,
    "eus_exams_eu_opeosakiceladoreu": 0.0,
    "eus_exams_eu_opeosakienfeu": 0.0,
    "eus_exams_eu_opeosakioperarioeu": 0.0,
    "eus_exams_eu_opeosakitecnicoeu": 0.0,
    "eus_exams_eu_opeosakivarioseu": 0.0,
    "eus_exams_eu_osakidetza1e": 0.0,
    "eus_exams_eu_osakidetza2e": 0.0,
    "eus_exams_eu_osakidetza3e": 0.0,
    "eus_exams_eu_osakidetza5e": 0.0,
    "eus_exams_eu_osakidetza6e": 0.0,
    "eus_exams_eu_osakidetza7e": 0.0
  },
  "n-shot": {
    "eus_exams_eu_ejadministrari": 5,
    "eus_exams_eu_ejlaguntza": 5,
    "eus_exams_eu_ejlaguntzaile": 5,
    "eus_exams_eu_ejteknikari": 5,
    "eus_exams_eu_opebilbaoeu": 5,
    "eus_exams_eu_opeehuadmineu": 5,
    "eus_exams_eu_opeehuauxeu": 5,
    "eus_exams_eu_opeehubiblioeu": 5,
    "eus_exams_eu_opeehuderechoeu": 5,
    "eus_exams_eu_opeehueconomicaseu": 5,
    "eus_exams_eu_opeehuempresarialeseu": 5,
    "eus_exams_eu_opeehusubalternoeu": 5,
    "eus_exams_eu_opeehutecnicoeu": 5,
    "eus_exams_eu_opeehuteknikarib": 5,
    "eus_exams_eu_opegasteizkoudala": 5,
    "eus_exams_eu_opeosakiadmineu": 5,
    "eus_exams_eu_opeosakiauxenfeu": 5,
    "eus_exams_eu_opeosakiauxeu": 5,
    "eus_exams_eu_opeosakiceladoreu": 5,
    "eus_exams_eu_opeosakienfeu": 5,
    "eus_exams_eu_opeosakioperarioeu": 5,
    "eus_exams_eu_opeosakitecnicoeu": 5,
    "eus_exams_eu_opeosakivarioseu": 5,
    "eus_exams_eu_osakidetza1e": 5,
    "eus_exams_eu_osakidetza2e": 5,
    "eus_exams_eu_osakidetza3e": 5,
    "eus_exams_eu_osakidetza5e": 5,
    "eus_exams_eu_osakidetza6e": 5,
    "eus_exams_eu_osakidetza7e": 5
  },
  "higher_is_better": {
    "eus_exams_eu_ejadministrari": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejlaguntza": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejlaguntzaile": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejteknikari": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opebilbaoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuadmineu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuauxeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehubiblioeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuderechoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuteknikarib": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opegasteizkoudala": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiadmineu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiauxeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakienfeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakivarioseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza1e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza2e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza3e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza5e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza6e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza7e": {
      "acc": true,
      "acc_norm": true
    }
  },
  "n-samples": {
    "eus_exams_eu_opeehuderechoeu": {
      "original": 700,
      "effective": 700
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "original": 280,
      "effective": 280
    },
    "eus_exams_eu_opebilbaoeu": {
      "original": 630,
      "effective": 630
    },
    "eus_exams_eu_osakidetza7e": {
      "original": 2163,
      "effective": 2163
    },
    "eus_exams_eu_opegasteizkoudala": {
      "original": 360,
      "effective": 360
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "original": 351,
      "effective": 351
    },
    "eus_exams_eu_ejteknikari": {
      "original": 687,
      "effective": 687
    },
    "eus_exams_eu_opeehuauxeu": {
      "original": 450,
      "effective": 450
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "original": 131,
      "effective": 131
    },
    "eus_exams_eu_opeehubiblioeu": {
      "original": 599,
      "effective": 599
    },
    "eus_exams_eu_osakidetza2e": {
      "original": 748,
      "effective": 748
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "original": 321,
      "effective": 321
    },
    "eus_exams_eu_opeehuteknikarib": {
      "original": 599,
      "effective": 599
    },
    "eus_exams_eu_ejlaguntzaile": {
      "original": 697,
      "effective": 697
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "original": 400,
      "effective": 400
    },
    "eus_exams_eu_osakidetza6e": {
      "original": 1000,
      "effective": 1000
    },
    "eus_exams_eu_opeosakivarioseu": {
      "original": 266,
      "effective": 266
    },
    "eus_exams_eu_opeosakienfeu": {
      "original": 373,
      "effective": 373
    },
    "eus_exams_eu_osakidetza5e": {
      "original": 650,
      "effective": 650
    },
    "eus_exams_eu_opeosakiauxeu": {
      "original": 165,
      "effective": 165
    },
    "eus_exams_eu_opeehuadmineu": {
      "original": 499,
      "effective": 499
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "original": 167,
      "effective": 167
    },
    "eus_exams_eu_osakidetza3e": {
      "original": 549,
      "effective": 549
    },
    "eus_exams_eu_ejadministrari": {
      "original": 696,
      "effective": 696
    },
    "eus_exams_eu_ejlaguntza": {
      "original": 498,
      "effective": 498
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "original": 699,
      "effective": 699
    },
    "eus_exams_eu_opeosakiadmineu": {
      "original": 236,
      "effective": 236
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "original": 163,
      "effective": 163
    },
    "eus_exams_eu_osakidetza1e": {
      "original": 647,
      "effective": 647
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/gscratch5/users/asalem/cpt-ift/model/ift-llama-eus-en-alpaca-lr1e04-10ksteps/checkpoint-50,parallelize=True",
    "model_num_parameters": 6738423808,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "",
    "batch_size": 1,
    "batch_sizes": [],
    "device": "cuda",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "a4ba02f",
  "date": 1740408768.2040343,
  "pretty_env_info": "PyTorch version: 2.6.0+cu124\nIs debug build: False\nCUDA used to build PyTorch: 12.4\nROCM used to build PyTorch: N/A\n\nOS: Rocky Linux 8.4 (Green Obsidian) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-4)\nClang version: Could not collect\nCMake version: Could not collect\nLibc version: glibc-2.28\n\nPython version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-305.19.1.el8_4.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: Could not collect\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\nGPU 2: NVIDIA A100-SXM4-80GB\nGPU 3: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 535.104.12\ncuDNN version: Probably one of the following:\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.2.1\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              128\nOn-line CPU(s) list: 0-127\nThread(s) per core:  2\nCore(s) per socket:  32\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           AuthenticAMD\nCPU family:          25\nModel:               1\nModel name:          AMD EPYC 7513 32-Core Processor\nStepping:            1\nCPU MHz:             3503.910\nCPU max MHz:         2600.0000\nCPU min MHz:         1500.0000\nBogoMIPS:            5190.38\nVirtualization:      AMD-V\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            512K\nL3 cache:            32768K\nNUMA node0 CPU(s):   0-31,64-95\nNUMA node1 CPU(s):   32-63,96-127\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate sme ssbd mba sev ibrs ibpb stibp vmmcall sev_es fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm\n\nVersions of relevant libraries:\n[pip3] numpy==2.2.2\n[pip3] nvidia-cublas-cu12==12.4.5.8\n[pip3] nvidia-cuda-cupti-cu12==12.4.127\n[pip3] nvidia-cuda-nvrtc-cu12==12.4.127\n[pip3] nvidia-cuda-runtime-cu12==12.4.127\n[pip3] nvidia-cudnn-cu12==9.1.0.70\n[pip3] nvidia-cufft-cu12==11.2.1.3\n[pip3] nvidia-curand-cu12==10.3.5.147\n[pip3] nvidia-cusolver-cu12==11.6.1.9\n[pip3] nvidia-cusparse-cu12==12.3.1.170\n[pip3] nvidia-cusparselt-cu12==0.6.2\n[pip3] nvidia-nccl-cu12==2.21.5\n[pip3] nvidia-nvjitlink-cu12==12.4.127\n[pip3] nvidia-nvtx-cu12==12.4.127\n[pip3] torch==2.6.0\n[pip3] triton==3.2.0\n[conda] _anaconda_depends         2024.02             py311_mkl_1  \n[conda] blas                      1.0                         mkl  \n[conda] mkl                       2023.1.0         h213fc3f_46344  \n[conda] mkl-service               2.4.0           py311h5eee18b_1  \n[conda] mkl_fft                   1.3.8           py311h5eee18b_0  \n[conda] mkl_random                1.2.4           py311hdb19cb5_0  \n[conda] numpy                     1.26.4          py311h08b1b3b_0  \n[conda] numpy-base                1.26.4          py311hf175353_0  \n[conda] numpydoc                  1.5.0           py311h06a4308_0  \n[conda] nvidia-cublas-cu12        12.4.5.8                 pypi_0    pypi\n[conda] nvidia-cuda-cupti-cu12    12.4.127                 pypi_0    pypi\n[conda] nvidia-cuda-nvrtc-cu12    12.4.127                 pypi_0    pypi\n[conda] nvidia-cuda-runtime-cu12  12.4.127                 pypi_0    pypi\n[conda] nvidia-cudnn-cu12         9.1.0.70                 pypi_0    pypi\n[conda] nvidia-cufft-cu12         11.2.1.3                 pypi_0    pypi\n[conda] nvidia-curand-cu12        10.3.5.147               pypi_0    pypi\n[conda] nvidia-cusolver-cu12      11.6.1.9                 pypi_0    pypi\n[conda] nvidia-cusparse-cu12      12.3.1.170               pypi_0    pypi\n[conda] nvidia-nccl-cu12          2.21.5                   pypi_0    pypi\n[conda] nvidia-nvjitlink-cu12     12.4.127                 pypi_0    pypi\n[conda] nvidia-nvtx-cu12          12.4.127                 pypi_0    pypi\n[conda] torch                     2.5.1                    pypi_0    pypi\n[conda] triton                    3.1.0                    pypi_0    pypi",
  "transformers_version": "4.48.3",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<|end_of_text|>",
    "32000"
  ],
  "tokenizer_eos_token": [
    "</s>",
    "2"
  ],
  "tokenizer_bos_token": [
    "<s>",
    "1"
  ],
  "eot_token_id": 2,
  "max_length": 8192,
  "task_hashes": {
    "eus_exams_eu_opeehuderechoeu": "866bff771dfb59b6f93069113b4fcccd8a1d67dc8cd4383a0b94ceeb3e696784",
    "eus_exams_eu_opeehuempresarialeseu": "2624f73c16e2dbf3027d60b0f637d1117fd71d57327d428c12284497459a67de",
    "eus_exams_eu_opebilbaoeu": "aa73a459d991d61b821cbee4a6fa683f7da4730ccf142991a5e03d2a074c1937",
    "eus_exams_eu_osakidetza7e": "df458a123236527e2ee9cde8e271b93f21cecf1959d4450d3b616ec97fe18b80",
    "eus_exams_eu_opegasteizkoudala": "7859195dc2e0a4811bad0b0ee6b7e193c2558fb67a3567d18cd88feabf2c699d",
    "eus_exams_eu_opeehueconomicaseu": "446a29112c6b41cd0957fbfeeedc7d2f9c759fe57e940eb457ddcfb0312a06f2",
    "eus_exams_eu_ejteknikari": "7ec0740656a3cadd9a2b3a725670f3001c2f5aa63a079e36940357faa9e1dbeb",
    "eus_exams_eu_opeehuauxeu": "50ecd00655cbad77bed6564cdcb9fc6d9fd394db25ea404453d06e4b2f839ad2",
    "eus_exams_eu_opeosakioperarioeu": "28cd320291d1fb63353ecaf85a0adb0fa8686e992cc24c657561e8986d58f8b8",
    "eus_exams_eu_opeehubiblioeu": "0baf8d55c275f33e66faaa0bf251b0bdb10aefedd81c44f2766496be8ee29ff1",
    "eus_exams_eu_osakidetza2e": "675b52fedd657789240ef37021f4b37a69e161dac6dcbe7dd8f53d1b7a75ed19",
    "eus_exams_eu_opeosakitecnicoeu": "fad7b310cd2d91396f3270994b44a2b84af8a8d51e10ea94f41760c64c60085f",
    "eus_exams_eu_opeehuteknikarib": "e30b94e1a83c46ee964cccfcd1c43d5b8e91828ba855a26afdfcba798f9eeedb",
    "eus_exams_eu_ejlaguntzaile": "c349d3d950b35dfa444bcc30a916bbe9c71d100ff5949b01e0fa2289091b0550",
    "eus_exams_eu_opeehusubalternoeu": "0084abd0626cd4a3201c5a775f901e3e727835d9544355a8b79d762e3243dd45",
    "eus_exams_eu_osakidetza6e": "403a02a3cf8681d0eeaddd4dff2098c08f156408162667e9ca8de580840518a5",
    "eus_exams_eu_opeosakivarioseu": "8098b5ca51c8257a58896305b3ecc384cb5325ea7d9b65a692e27ab247406945",
    "eus_exams_eu_opeosakienfeu": "cb33e3f33a81913a5e983f8c45d0fb830287a2a3ee1ee43846beb90d27aa55c0",
    "eus_exams_eu_osakidetza5e": "de8da44ce58b60ecc52e5f01118ace3b88f9331b5c479c07318640b539b7cc58",
    "eus_exams_eu_opeosakiauxeu": "a5a7751476daf86dea79dee0109c13e71bf181337113a2a353d0b9ba1fe9883a",
    "eus_exams_eu_opeehuadmineu": "c934094bb8da42674393f82a6e6444bcb5acc4b4920c36e0f94de5b5881b1b17",
    "eus_exams_eu_opeosakiauxenfeu": "449772d4b6fabc9d58582fa1b62a2bed104930f31f52363b881a4df47c52a2e1",
    "eus_exams_eu_osakidetza3e": "7d15f35dcbba10251e3c48e51482d507c948577c3d98d1928a52df6a9232e338",
    "eus_exams_eu_ejadministrari": "c49b08ceaa8e26d681c429055ac7344ed9a9f0c7e65790fda7ad793414e37c1b",
    "eus_exams_eu_ejlaguntza": "7fd172d852a4fd17f15b42518962363bede446663e4a3c7538987d3aabadca61",
    "eus_exams_eu_opeehutecnicoeu": "5e99f2e29556e89d097a8486f641073d1f2d89052382dd4a70817e00c76de70b",
    "eus_exams_eu_opeosakiadmineu": "7900ecb42ee7d3251c59c827934e4cd17f58750b5b99010d30a8a01df5e5a230",
    "eus_exams_eu_opeosakiceladoreu": "793700b56e39777c760750e59b55a54b0063367ea9eb6a8518d839ca9ea9cc3c",
    "eus_exams_eu_osakidetza1e": "43fd08062660d3bc6546cbde2f69af4b8af39387dc45b2d9ac261c5843ccfddb"
  },
  "model_source": "hf",
  "model_name": "/gscratch5/users/asalem/cpt-ift/model/ift-llama-eus-en-alpaca-lr1e04-10ksteps/checkpoint-50",
  "model_name_sanitized": "__gscratch5__users__asalem__cpt-ift__model__ift-llama-eus-en-alpaca-lr1e04-10ksteps__checkpoint-50",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 13645835.875358576,
  "end_time": 13647766.44338855,
  "total_evaluation_time_seconds": "1930.568029973656"
}