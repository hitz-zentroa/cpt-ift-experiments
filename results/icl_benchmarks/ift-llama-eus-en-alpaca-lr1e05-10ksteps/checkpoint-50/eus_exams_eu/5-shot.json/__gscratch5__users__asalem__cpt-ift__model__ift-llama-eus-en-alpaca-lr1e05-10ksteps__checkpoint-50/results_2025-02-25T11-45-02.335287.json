{
  "results": {
    "eus_exams_eu_ejadministrari": {
      "alias": "eus_exams_eu_ejadministrari",
      "acc,none": 0.22844827586206898,
      "acc_stderr,none": 0.01592516948704031,
      "acc_norm,none": 0.22844827586206898,
      "acc_norm_stderr,none": 0.01592516948704031
    },
    "eus_exams_eu_ejlaguntza": {
      "alias": "eus_exams_eu_ejlaguntza",
      "acc,none": 0.23293172690763053,
      "acc_stderr,none": 0.018960646394177317,
      "acc_norm,none": 0.23293172690763053,
      "acc_norm_stderr,none": 0.018960646394177317
    },
    "eus_exams_eu_ejlaguntzaile": {
      "alias": "eus_exams_eu_ejlaguntzaile",
      "acc,none": 0.27259684361549497,
      "acc_stderr,none": 0.016878870542338022,
      "acc_norm,none": 0.27259684361549497,
      "acc_norm_stderr,none": 0.016878870542338022
    },
    "eus_exams_eu_ejteknikari": {
      "alias": "eus_exams_eu_ejteknikari",
      "acc,none": 0.24163027656477437,
      "acc_stderr,none": 0.016343840327033784,
      "acc_norm,none": 0.24163027656477437,
      "acc_norm_stderr,none": 0.016343840327033784
    },
    "eus_exams_eu_opebilbaoeu": {
      "alias": "eus_exams_eu_opebilbaoeu",
      "acc,none": 0.26031746031746034,
      "acc_stderr,none": 0.0174964125403671,
      "acc_norm,none": 0.26031746031746034,
      "acc_norm_stderr,none": 0.0174964125403671
    },
    "eus_exams_eu_opeehuadmineu": {
      "alias": "eus_exams_eu_opeehuadmineu",
      "acc,none": 0.27655310621242485,
      "acc_stderr,none": 0.020043701534351404,
      "acc_norm,none": 0.27655310621242485,
      "acc_norm_stderr,none": 0.020043701534351404
    },
    "eus_exams_eu_opeehuauxeu": {
      "alias": "eus_exams_eu_opeehuauxeu",
      "acc,none": 0.28,
      "acc_stderr,none": 0.02118956754699132,
      "acc_norm,none": 0.28,
      "acc_norm_stderr,none": 0.02118956754699132
    },
    "eus_exams_eu_opeehubiblioeu": {
      "alias": "eus_exams_eu_opeehubiblioeu",
      "acc,none": 0.24540901502504173,
      "acc_stderr,none": 0.01759747959917211,
      "acc_norm,none": 0.24540901502504173,
      "acc_norm_stderr,none": 0.01759747959917211
    },
    "eus_exams_eu_opeehuderechoeu": {
      "alias": "eus_exams_eu_opeehuderechoeu",
      "acc,none": 0.22857142857142856,
      "acc_stderr,none": 0.015882550443842725,
      "acc_norm,none": 0.22857142857142856,
      "acc_norm_stderr,none": 0.015882550443842725
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "alias": "eus_exams_eu_opeehueconomicaseu",
      "acc,none": 0.245014245014245,
      "acc_stderr,none": 0.02298957930108736,
      "acc_norm,none": 0.245014245014245,
      "acc_norm_stderr,none": 0.02298957930108736
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "alias": "eus_exams_eu_opeehuempresarialeseu",
      "acc,none": 0.25357142857142856,
      "acc_stderr,none": 0.026046068862062243,
      "acc_norm,none": 0.25357142857142856,
      "acc_norm_stderr,none": 0.026046068862062243
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "alias": "eus_exams_eu_opeehusubalternoeu",
      "acc,none": 0.265,
      "acc_stderr,none": 0.02209429552479196,
      "acc_norm,none": 0.265,
      "acc_norm_stderr,none": 0.02209429552479196
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "alias": "eus_exams_eu_opeehutecnicoeu",
      "acc,none": 0.27467811158798283,
      "acc_stderr,none": 0.016894669756837837,
      "acc_norm,none": 0.27467811158798283,
      "acc_norm_stderr,none": 0.016894669756837837
    },
    "eus_exams_eu_opeehuteknikarib": {
      "alias": "eus_exams_eu_opeehuteknikarib",
      "acc,none": 0.2637729549248748,
      "acc_stderr,none": 0.018020648838865477,
      "acc_norm,none": 0.2637729549248748,
      "acc_norm_stderr,none": 0.018020648838865477
    },
    "eus_exams_eu_opegasteizkoudala": {
      "alias": "eus_exams_eu_opegasteizkoudala",
      "acc,none": 0.32222222222222224,
      "acc_stderr,none": 0.024664606024215982,
      "acc_norm,none": 0.32222222222222224,
      "acc_norm_stderr,none": 0.024664606024215982
    },
    "eus_exams_eu_opeosakiadmineu": {
      "alias": "eus_exams_eu_opeosakiadmineu",
      "acc,none": 0.2669491525423729,
      "acc_stderr,none": 0.02885674835335504,
      "acc_norm,none": 0.2669491525423729,
      "acc_norm_stderr,none": 0.02885674835335504
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "alias": "eus_exams_eu_opeosakiauxenfeu",
      "acc,none": 0.24550898203592814,
      "acc_stderr,none": 0.03340463153945587,
      "acc_norm,none": 0.24550898203592814,
      "acc_norm_stderr,none": 0.03340463153945587
    },
    "eus_exams_eu_opeosakiauxeu": {
      "alias": "eus_exams_eu_opeosakiauxeu",
      "acc,none": 0.28484848484848485,
      "acc_stderr,none": 0.03524390844511785,
      "acc_norm,none": 0.28484848484848485,
      "acc_norm_stderr,none": 0.03524390844511785
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "alias": "eus_exams_eu_opeosakiceladoreu",
      "acc,none": 0.27607361963190186,
      "acc_stderr,none": 0.035123852837050454,
      "acc_norm,none": 0.27607361963190186,
      "acc_norm_stderr,none": 0.035123852837050454
    },
    "eus_exams_eu_opeosakienfeu": {
      "alias": "eus_exams_eu_opeosakienfeu",
      "acc,none": 0.24396782841823056,
      "acc_stderr,none": 0.02226716609255301,
      "acc_norm,none": 0.24396782841823056,
      "acc_norm_stderr,none": 0.02226716609255301
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "alias": "eus_exams_eu_opeosakioperarioeu",
      "acc,none": 0.2748091603053435,
      "acc_stderr,none": 0.03915345408847834,
      "acc_norm,none": 0.2748091603053435,
      "acc_norm_stderr,none": 0.03915345408847834
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "alias": "eus_exams_eu_opeosakitecnicoeu",
      "acc,none": 0.2554517133956386,
      "acc_stderr,none": 0.024379559542708564,
      "acc_norm,none": 0.2554517133956386,
      "acc_norm_stderr,none": 0.024379559542708564
    },
    "eus_exams_eu_opeosakivarioseu": {
      "alias": "eus_exams_eu_opeosakivarioseu",
      "acc,none": 0.2781954887218045,
      "acc_stderr,none": 0.027527191275800257,
      "acc_norm,none": 0.2781954887218045,
      "acc_norm_stderr,none": 0.027527191275800257
    },
    "eus_exams_eu_osakidetza1e": {
      "alias": "eus_exams_eu_osakidetza1e",
      "acc,none": 0.24420401854714066,
      "acc_stderr,none": 0.016902947142251826,
      "acc_norm,none": 0.24420401854714066,
      "acc_norm_stderr,none": 0.016902947142251826
    },
    "eus_exams_eu_osakidetza2e": {
      "alias": "eus_exams_eu_osakidetza2e",
      "acc,none": 0.232620320855615,
      "acc_stderr,none": 0.015458547030019074,
      "acc_norm,none": 0.232620320855615,
      "acc_norm_stderr,none": 0.015458547030019074
    },
    "eus_exams_eu_osakidetza3e": {
      "alias": "eus_exams_eu_osakidetza3e",
      "acc,none": 0.23861566484517305,
      "acc_stderr,none": 0.018207954733468517,
      "acc_norm,none": 0.23861566484517305,
      "acc_norm_stderr,none": 0.018207954733468517
    },
    "eus_exams_eu_osakidetza5e": {
      "alias": "eus_exams_eu_osakidetza5e",
      "acc,none": 0.26,
      "acc_stderr,none": 0.017217900170653642,
      "acc_norm,none": 0.26,
      "acc_norm_stderr,none": 0.017217900170653642
    },
    "eus_exams_eu_osakidetza6e": {
      "alias": "eus_exams_eu_osakidetza6e",
      "acc,none": 0.251,
      "acc_stderr,none": 0.013718133516888775,
      "acc_norm,none": 0.251,
      "acc_norm_stderr,none": 0.013718133516888775
    },
    "eus_exams_eu_osakidetza7e": {
      "alias": "eus_exams_eu_osakidetza7e",
      "acc,none": 0.2561257512713823,
      "acc_stderr,none": 0.009387469525493469,
      "acc_norm,none": 0.2561257512713823,
      "acc_norm_stderr,none": 0.009387469525493469
    }
  },
  "group_subtasks": {
    "eus_exams_eu_osakidetza1e": [],
    "eus_exams_eu_opeosakiceladoreu": [],
    "eus_exams_eu_opeosakiadmineu": [],
    "eus_exams_eu_opeehutecnicoeu": [],
    "eus_exams_eu_ejlaguntza": [],
    "eus_exams_eu_ejadministrari": [],
    "eus_exams_eu_osakidetza3e": [],
    "eus_exams_eu_opeosakiauxenfeu": [],
    "eus_exams_eu_opeehuadmineu": [],
    "eus_exams_eu_opeosakiauxeu": [],
    "eus_exams_eu_osakidetza5e": [],
    "eus_exams_eu_opeosakienfeu": [],
    "eus_exams_eu_opeosakivarioseu": [],
    "eus_exams_eu_osakidetza6e": [],
    "eus_exams_eu_opeehusubalternoeu": [],
    "eus_exams_eu_ejlaguntzaile": [],
    "eus_exams_eu_opeehuteknikarib": [],
    "eus_exams_eu_opeosakitecnicoeu": [],
    "eus_exams_eu_osakidetza2e": [],
    "eus_exams_eu_opeehubiblioeu": [],
    "eus_exams_eu_opeosakioperarioeu": [],
    "eus_exams_eu_opeehuauxeu": [],
    "eus_exams_eu_ejteknikari": [],
    "eus_exams_eu_opeehueconomicaseu": [],
    "eus_exams_eu_opegasteizkoudala": [],
    "eus_exams_eu_osakidetza7e": [],
    "eus_exams_eu_opebilbaoeu": [],
    "eus_exams_eu_opeehuempresarialeseu": [],
    "eus_exams_eu_opeehuderechoeu": []
  },
  "configs": {
    "eus_exams_eu_ejadministrari": {
      "task": "eus_exams_eu_ejadministrari",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejadministrari",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejlaguntza": {
      "task": "eus_exams_eu_ejlaguntza",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejlaguntza",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejlaguntzaile": {
      "task": "eus_exams_eu_ejlaguntzaile",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejlaguntzaile",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_ejteknikari": {
      "task": "eus_exams_eu_ejteknikari",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_ejteknikari",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opebilbaoeu": {
      "task": "eus_exams_eu_opebilbaoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opebilbaoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuadmineu": {
      "task": "eus_exams_eu_opeehuadmineu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuadmineu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuauxeu": {
      "task": "eus_exams_eu_opeehuauxeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuauxeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehubiblioeu": {
      "task": "eus_exams_eu_opeehubiblioeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehubiblioeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuderechoeu": {
      "task": "eus_exams_eu_opeehuderechoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuderechoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "task": "eus_exams_eu_opeehueconomicaseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehueconomicaseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "task": "eus_exams_eu_opeehuempresarialeseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuempresarialeseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "task": "eus_exams_eu_opeehusubalternoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehusubalternoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "task": "eus_exams_eu_opeehutecnicoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehutecnicoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeehuteknikarib": {
      "task": "eus_exams_eu_opeehuteknikarib",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeehuteknikarib",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opegasteizkoudala": {
      "task": "eus_exams_eu_opegasteizkoudala",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opegasteizkoudala",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiadmineu": {
      "task": "eus_exams_eu_opeosakiadmineu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiadmineu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "task": "eus_exams_eu_opeosakiauxenfeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiauxenfeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiauxeu": {
      "task": "eus_exams_eu_opeosakiauxeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiauxeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "task": "eus_exams_eu_opeosakiceladoreu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakiceladoreu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakienfeu": {
      "task": "eus_exams_eu_opeosakienfeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakienfeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "task": "eus_exams_eu_opeosakioperarioeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakioperarioeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "task": "eus_exams_eu_opeosakitecnicoeu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakitecnicoeu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_opeosakivarioseu": {
      "task": "eus_exams_eu_opeosakivarioseu",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_opeosakivarioseu",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza1e": {
      "task": "eus_exams_eu_osakidetza1e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza1e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza2e": {
      "task": "eus_exams_eu_osakidetza2e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza2e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza3e": {
      "task": "eus_exams_eu_osakidetza3e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza3e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza5e": {
      "task": "eus_exams_eu_osakidetza5e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza5e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza6e": {
      "task": "eus_exams_eu_osakidetza6e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza6e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    },
    "eus_exams_eu_osakidetza7e": {
      "task": "eus_exams_eu_osakidetza7e",
      "tag": [
        "eus_exams_eu"
      ],
      "dataset_path": "HiTZ/EusExams",
      "dataset_name": "eu_osakidetza7e",
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def process_docs(dataset: datasets.Dataset):\n    \"\"\"Filter out examples with no answer.\"\"\"\n\n    def valid_example(example: dict) -> bool:\n        \"\"\"Check if an example is valid.\"\"\"\n        if example[\"answer\"] not in [0, 1, 2, 3]:\n            return False\n        if example[\"candidates\"] == [\"\", \"\", \"\", \"\"]:\n            return False\n        return True\n\n    return dataset.filter(valid_example)\n",
      "doc_to_text": "Galdera: {{question}}\nA: {{candidates[0]}}\nB: {{candidates[1]}}\nC: {{candidates[2]}}\nD: {{candidates[3]}}\nErantzuna:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 0.0
      }
    }
  },
  "versions": {
    "eus_exams_eu_ejadministrari": 0.0,
    "eus_exams_eu_ejlaguntza": 0.0,
    "eus_exams_eu_ejlaguntzaile": 0.0,
    "eus_exams_eu_ejteknikari": 0.0,
    "eus_exams_eu_opebilbaoeu": 0.0,
    "eus_exams_eu_opeehuadmineu": 0.0,
    "eus_exams_eu_opeehuauxeu": 0.0,
    "eus_exams_eu_opeehubiblioeu": 0.0,
    "eus_exams_eu_opeehuderechoeu": 0.0,
    "eus_exams_eu_opeehueconomicaseu": 0.0,
    "eus_exams_eu_opeehuempresarialeseu": 0.0,
    "eus_exams_eu_opeehusubalternoeu": 0.0,
    "eus_exams_eu_opeehutecnicoeu": 0.0,
    "eus_exams_eu_opeehuteknikarib": 0.0,
    "eus_exams_eu_opegasteizkoudala": 0.0,
    "eus_exams_eu_opeosakiadmineu": 0.0,
    "eus_exams_eu_opeosakiauxenfeu": 0.0,
    "eus_exams_eu_opeosakiauxeu": 0.0,
    "eus_exams_eu_opeosakiceladoreu": 0.0,
    "eus_exams_eu_opeosakienfeu": 0.0,
    "eus_exams_eu_opeosakioperarioeu": 0.0,
    "eus_exams_eu_opeosakitecnicoeu": 0.0,
    "eus_exams_eu_opeosakivarioseu": 0.0,
    "eus_exams_eu_osakidetza1e": 0.0,
    "eus_exams_eu_osakidetza2e": 0.0,
    "eus_exams_eu_osakidetza3e": 0.0,
    "eus_exams_eu_osakidetza5e": 0.0,
    "eus_exams_eu_osakidetza6e": 0.0,
    "eus_exams_eu_osakidetza7e": 0.0
  },
  "n-shot": {
    "eus_exams_eu_ejadministrari": 5,
    "eus_exams_eu_ejlaguntza": 5,
    "eus_exams_eu_ejlaguntzaile": 5,
    "eus_exams_eu_ejteknikari": 5,
    "eus_exams_eu_opebilbaoeu": 5,
    "eus_exams_eu_opeehuadmineu": 5,
    "eus_exams_eu_opeehuauxeu": 5,
    "eus_exams_eu_opeehubiblioeu": 5,
    "eus_exams_eu_opeehuderechoeu": 5,
    "eus_exams_eu_opeehueconomicaseu": 5,
    "eus_exams_eu_opeehuempresarialeseu": 5,
    "eus_exams_eu_opeehusubalternoeu": 5,
    "eus_exams_eu_opeehutecnicoeu": 5,
    "eus_exams_eu_opeehuteknikarib": 5,
    "eus_exams_eu_opegasteizkoudala": 5,
    "eus_exams_eu_opeosakiadmineu": 5,
    "eus_exams_eu_opeosakiauxenfeu": 5,
    "eus_exams_eu_opeosakiauxeu": 5,
    "eus_exams_eu_opeosakiceladoreu": 5,
    "eus_exams_eu_opeosakienfeu": 5,
    "eus_exams_eu_opeosakioperarioeu": 5,
    "eus_exams_eu_opeosakitecnicoeu": 5,
    "eus_exams_eu_opeosakivarioseu": 5,
    "eus_exams_eu_osakidetza1e": 5,
    "eus_exams_eu_osakidetza2e": 5,
    "eus_exams_eu_osakidetza3e": 5,
    "eus_exams_eu_osakidetza5e": 5,
    "eus_exams_eu_osakidetza6e": 5,
    "eus_exams_eu_osakidetza7e": 5
  },
  "higher_is_better": {
    "eus_exams_eu_ejadministrari": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejlaguntza": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejlaguntzaile": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_ejteknikari": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opebilbaoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuadmineu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuauxeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehubiblioeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuderechoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeehuteknikarib": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opegasteizkoudala": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiadmineu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiauxeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakienfeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_opeosakivarioseu": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza1e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza2e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza3e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza5e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza6e": {
      "acc": true,
      "acc_norm": true
    },
    "eus_exams_eu_osakidetza7e": {
      "acc": true,
      "acc_norm": true
    }
  },
  "n-samples": {
    "eus_exams_eu_opeehuderechoeu": {
      "original": 700,
      "effective": 700
    },
    "eus_exams_eu_opeehuempresarialeseu": {
      "original": 280,
      "effective": 280
    },
    "eus_exams_eu_opebilbaoeu": {
      "original": 630,
      "effective": 630
    },
    "eus_exams_eu_osakidetza7e": {
      "original": 2163,
      "effective": 2163
    },
    "eus_exams_eu_opegasteizkoudala": {
      "original": 360,
      "effective": 360
    },
    "eus_exams_eu_opeehueconomicaseu": {
      "original": 351,
      "effective": 351
    },
    "eus_exams_eu_ejteknikari": {
      "original": 687,
      "effective": 687
    },
    "eus_exams_eu_opeehuauxeu": {
      "original": 450,
      "effective": 450
    },
    "eus_exams_eu_opeosakioperarioeu": {
      "original": 131,
      "effective": 131
    },
    "eus_exams_eu_opeehubiblioeu": {
      "original": 599,
      "effective": 599
    },
    "eus_exams_eu_osakidetza2e": {
      "original": 748,
      "effective": 748
    },
    "eus_exams_eu_opeosakitecnicoeu": {
      "original": 321,
      "effective": 321
    },
    "eus_exams_eu_opeehuteknikarib": {
      "original": 599,
      "effective": 599
    },
    "eus_exams_eu_ejlaguntzaile": {
      "original": 697,
      "effective": 697
    },
    "eus_exams_eu_opeehusubalternoeu": {
      "original": 400,
      "effective": 400
    },
    "eus_exams_eu_osakidetza6e": {
      "original": 1000,
      "effective": 1000
    },
    "eus_exams_eu_opeosakivarioseu": {
      "original": 266,
      "effective": 266
    },
    "eus_exams_eu_opeosakienfeu": {
      "original": 373,
      "effective": 373
    },
    "eus_exams_eu_osakidetza5e": {
      "original": 650,
      "effective": 650
    },
    "eus_exams_eu_opeosakiauxeu": {
      "original": 165,
      "effective": 165
    },
    "eus_exams_eu_opeehuadmineu": {
      "original": 499,
      "effective": 499
    },
    "eus_exams_eu_opeosakiauxenfeu": {
      "original": 167,
      "effective": 167
    },
    "eus_exams_eu_osakidetza3e": {
      "original": 549,
      "effective": 549
    },
    "eus_exams_eu_ejadministrari": {
      "original": 696,
      "effective": 696
    },
    "eus_exams_eu_ejlaguntza": {
      "original": 498,
      "effective": 498
    },
    "eus_exams_eu_opeehutecnicoeu": {
      "original": 699,
      "effective": 699
    },
    "eus_exams_eu_opeosakiadmineu": {
      "original": 236,
      "effective": 236
    },
    "eus_exams_eu_opeosakiceladoreu": {
      "original": 163,
      "effective": 163
    },
    "eus_exams_eu_osakidetza1e": {
      "original": 647,
      "effective": 647
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=/gscratch5/users/asalem/cpt-ift/model/ift-llama-eus-en-alpaca-lr1e05-10ksteps/checkpoint-50,parallelize=True",
    "model_num_parameters": 6738423808,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "",
    "batch_size": 1,
    "batch_sizes": [],
    "device": "cuda",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "a4ba02f",
  "date": 1740477728.8631701,
  "pretty_env_info": "PyTorch version: 2.6.0+cu124\nIs debug build: False\nCUDA used to build PyTorch: 12.4\nROCM used to build PyTorch: N/A\n\nOS: Rocky Linux 8.4 (Green Obsidian) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-4)\nClang version: Could not collect\nCMake version: Could not collect\nLibc version: glibc-2.28\n\nPython version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-305.19.1.el8_4.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: Could not collect\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\nGPU 2: NVIDIA A100-SXM4-80GB\nGPU 3: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 535.104.12\ncuDNN version: Probably one of the following:\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.2.1\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              128\nOn-line CPU(s) list: 0-127\nThread(s) per core:  2\nCore(s) per socket:  32\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           AuthenticAMD\nCPU family:          25\nModel:               1\nModel name:          AMD EPYC 7513 32-Core Processor\nStepping:            1\nCPU MHz:             3575.440\nCPU max MHz:         2600.0000\nCPU min MHz:         1500.0000\nBogoMIPS:            5190.38\nVirtualization:      AMD-V\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            512K\nL3 cache:            32768K\nNUMA node0 CPU(s):   0-31,64-95\nNUMA node1 CPU(s):   32-63,96-127\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate sme ssbd mba sev ibrs ibpb stibp vmmcall sev_es fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm\n\nVersions of relevant libraries:\n[pip3] numpy==2.2.2\n[pip3] nvidia-cublas-cu12==12.4.5.8\n[pip3] nvidia-cuda-cupti-cu12==12.4.127\n[pip3] nvidia-cuda-nvrtc-cu12==12.4.127\n[pip3] nvidia-cuda-runtime-cu12==12.4.127\n[pip3] nvidia-cudnn-cu12==9.1.0.70\n[pip3] nvidia-cufft-cu12==11.2.1.3\n[pip3] nvidia-curand-cu12==10.3.5.147\n[pip3] nvidia-cusolver-cu12==11.6.1.9\n[pip3] nvidia-cusparse-cu12==12.3.1.170\n[pip3] nvidia-cusparselt-cu12==0.6.2\n[pip3] nvidia-nccl-cu12==2.21.5\n[pip3] nvidia-nvjitlink-cu12==12.4.127\n[pip3] nvidia-nvtx-cu12==12.4.127\n[pip3] torch==2.6.0\n[pip3] triton==3.2.0\n[conda] numpy                     1.26.4                   pypi_0    pypi\n[conda] nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi\n[conda] nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi\n[conda] nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi\n[conda] nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi\n[conda] nvidia-cudnn-cu12         9.1.0.70                 pypi_0    pypi\n[conda] nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi\n[conda] nvidia-curand-cu12        10.3.2.106               pypi_0    pypi\n[conda] nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi\n[conda] nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi\n[conda] nvidia-nccl-cu12          2.20.5                   pypi_0    pypi\n[conda] nvidia-nvjitlink-cu12     12.4.127                 pypi_0    pypi\n[conda] nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi\n[conda] optree                    0.11.0                   pypi_0    pypi\n[conda] torch                     2.4.1                    pypi_0    pypi\n[conda] torchvision               0.19.1                   pypi_0    pypi\n[conda] triton                    3.0.0                    pypi_0    pypi",
  "transformers_version": "4.48.3",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<|end_of_text|>",
    "32000"
  ],
  "tokenizer_eos_token": [
    "</s>",
    "2"
  ],
  "tokenizer_bos_token": [
    "<s>",
    "1"
  ],
  "eot_token_id": 2,
  "max_length": 8192,
  "task_hashes": {
    "eus_exams_eu_opeehuderechoeu": "866bff771dfb59b6f93069113b4fcccd8a1d67dc8cd4383a0b94ceeb3e696784",
    "eus_exams_eu_opeehuempresarialeseu": "2624f73c16e2dbf3027d60b0f637d1117fd71d57327d428c12284497459a67de",
    "eus_exams_eu_opebilbaoeu": "aa73a459d991d61b821cbee4a6fa683f7da4730ccf142991a5e03d2a074c1937",
    "eus_exams_eu_osakidetza7e": "df458a123236527e2ee9cde8e271b93f21cecf1959d4450d3b616ec97fe18b80",
    "eus_exams_eu_opegasteizkoudala": "7859195dc2e0a4811bad0b0ee6b7e193c2558fb67a3567d18cd88feabf2c699d",
    "eus_exams_eu_opeehueconomicaseu": "446a29112c6b41cd0957fbfeeedc7d2f9c759fe57e940eb457ddcfb0312a06f2",
    "eus_exams_eu_ejteknikari": "7ec0740656a3cadd9a2b3a725670f3001c2f5aa63a079e36940357faa9e1dbeb",
    "eus_exams_eu_opeehuauxeu": "50ecd00655cbad77bed6564cdcb9fc6d9fd394db25ea404453d06e4b2f839ad2",
    "eus_exams_eu_opeosakioperarioeu": "28cd320291d1fb63353ecaf85a0adb0fa8686e992cc24c657561e8986d58f8b8",
    "eus_exams_eu_opeehubiblioeu": "0baf8d55c275f33e66faaa0bf251b0bdb10aefedd81c44f2766496be8ee29ff1",
    "eus_exams_eu_osakidetza2e": "675b52fedd657789240ef37021f4b37a69e161dac6dcbe7dd8f53d1b7a75ed19",
    "eus_exams_eu_opeosakitecnicoeu": "fad7b310cd2d91396f3270994b44a2b84af8a8d51e10ea94f41760c64c60085f",
    "eus_exams_eu_opeehuteknikarib": "e30b94e1a83c46ee964cccfcd1c43d5b8e91828ba855a26afdfcba798f9eeedb",
    "eus_exams_eu_ejlaguntzaile": "c349d3d950b35dfa444bcc30a916bbe9c71d100ff5949b01e0fa2289091b0550",
    "eus_exams_eu_opeehusubalternoeu": "0084abd0626cd4a3201c5a775f901e3e727835d9544355a8b79d762e3243dd45",
    "eus_exams_eu_osakidetza6e": "403a02a3cf8681d0eeaddd4dff2098c08f156408162667e9ca8de580840518a5",
    "eus_exams_eu_opeosakivarioseu": "8098b5ca51c8257a58896305b3ecc384cb5325ea7d9b65a692e27ab247406945",
    "eus_exams_eu_opeosakienfeu": "cb33e3f33a81913a5e983f8c45d0fb830287a2a3ee1ee43846beb90d27aa55c0",
    "eus_exams_eu_osakidetza5e": "de8da44ce58b60ecc52e5f01118ace3b88f9331b5c479c07318640b539b7cc58",
    "eus_exams_eu_opeosakiauxeu": "a5a7751476daf86dea79dee0109c13e71bf181337113a2a353d0b9ba1fe9883a",
    "eus_exams_eu_opeehuadmineu": "c934094bb8da42674393f82a6e6444bcb5acc4b4920c36e0f94de5b5881b1b17",
    "eus_exams_eu_opeosakiauxenfeu": "449772d4b6fabc9d58582fa1b62a2bed104930f31f52363b881a4df47c52a2e1",
    "eus_exams_eu_osakidetza3e": "7d15f35dcbba10251e3c48e51482d507c948577c3d98d1928a52df6a9232e338",
    "eus_exams_eu_ejadministrari": "c49b08ceaa8e26d681c429055ac7344ed9a9f0c7e65790fda7ad793414e37c1b",
    "eus_exams_eu_ejlaguntza": "7fd172d852a4fd17f15b42518962363bede446663e4a3c7538987d3aabadca61",
    "eus_exams_eu_opeehutecnicoeu": "5e99f2e29556e89d097a8486f641073d1f2d89052382dd4a70817e00c76de70b",
    "eus_exams_eu_opeosakiadmineu": "7900ecb42ee7d3251c59c827934e4cd17f58750b5b99010d30a8a01df5e5a230",
    "eus_exams_eu_opeosakiceladoreu": "793700b56e39777c760750e59b55a54b0063367ea9eb6a8518d839ca9ea9cc3c",
    "eus_exams_eu_osakidetza1e": "43fd08062660d3bc6546cbde2f69af4b8af39387dc45b2d9ac261c5843ccfddb"
  },
  "model_source": "hf",
  "model_name": "/gscratch5/users/asalem/cpt-ift/model/ift-llama-eus-en-alpaca-lr1e05-10ksteps/checkpoint-50",
  "model_name_sanitized": "__gscratch5__users__asalem__cpt-ift__model__ift-llama-eus-en-alpaca-lr1e05-10ksteps__checkpoint-50",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 13714798.199687876,
  "end_time": 13717378.432381164,
  "total_evaluation_time_seconds": "2580.2326932884753"
}